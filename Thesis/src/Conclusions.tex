
Measuring similarities between software systems has been considered as a daunting task. Furthermore, considering the miscellaneousness of artifacts in open source software repositories, similarity computation becomes more complicated as many artifacts and several cross relationships prevail. Thus, choosing the right tool to compute software similarity is a question that may arise at any time. The current thesis attempts to address one of the issues in software similarity computation by performing a comprehensive evaluation on various techniques. We performed a literature review on different approaches for computing software similarity. We see that depending on the set of mined features, there are two main types of software similarity computation techniques. The first type is \textit{Low-level Similarity} where only low-level data, e.g., source code, byte code, function calls, API reference, etc. is considered. The second type is \textit{High-level Similarity} and it detects the semantic similarity using metadata, such as: topic distribution, readme file, description, star events, etc. Source code is not taken into account.

Most low-level similarity algorithms attempt to represent source code (and API calls) in a term-document matrix and then apply SVD to reduce dimensionality. The similarity is then computed as the cosine similarity between feature vectors. Among others, \MUDABlue \cite{10.1109/APSEC.2004.69}, \CLAN \cite{McMillan:2012:DSS:2337223.2337267}, and CLANdroid \cite{10.1109ICPC.2016.7503721} belong to this category. \CLAN includes API calls for computing similarity, whereas, by \MUDABlue, every word appearing in source code files is integrated into the term-document matrix. This makes the difference in the performance of the two algorithms in a way that the similarity scores of \CLAN reflect better the perception of humans of similarity than those of \MUDABlue. In contrast, high-level similarity techniques do not consider source code for similarity computation. They characterize software by exploiting available features such as descriptions, user reviews, and \code{README.MD} file. The similarity is computed as the cosine similarity of the corresponding feature vectors. For computing similarity between mobile applications, other specific features such as images and permissions are also incorporated. 

We re-implement four software similarity tools and conduct an empirical evaluation using a dataset of $580$ GitHub Java projects collected from GitHub. The obtained results are promising: by considering \MUDABlue, \CLAN, and \RepoPal as baseline, we demonstrated that \CrossSim is considered as a good candidate for computing similarities among open source software projects. \CrossSim is an extensible and flexible approach to calculate the similarity of open source projects. It can deal with various types of input project information that is represented in a homogeneous manner by means of graphs. By means of the proposed graph representation, it is possible to transform the relationships among various artifacts, e.g. developers, API utilizations, source code, interactions, into a mathematically computable format. In this sense, \CrossSim is a versatile similarity tool as it can accept various input features regardless of their format. %As long as the inputs are integrated into the graph, the similarity between different artifacts can then be computed using the augmented graph. 

%One of the most hard issue faced was related to the physical memory required to compute the Latent Semantic Analysis, for \MUDABlue in particular we got something like $700,000$ terms. This means that the required memory, only to manage the matrix was about 3Gb, this excluding all the memory used for other data structures and for the parsing. That's why we put a bound for the Eclipse virtual memory up to 8Gb and worked in two phase. During the first phase we collected all the terms by parsing everything and then, after an IDE restart, computing the LSA.





%\begin{itemize}
%	\item Study and Analysis of the problem. In this phase we have analyzed the similarity problem discovering that is well known problem studied in order to find a solution to some very interesting problems such as: (plagiarism detection, information retrieval,text classification, document clustering, topic detection and so on).In order to validate our novel approach we eventually decided to study in detail and implement two similarity calculator approaches: MudaBlue and Clan.
%	\item Implementation. The implementation phase covered a lot of aspects. First of all was necessary analyzing the projects by parsing each \emph{.java} file and then summing up everything in a \emph{Term-Document matrix}. We applied then, the core of the apporaches, the \emph{Latent Semantic Analysis}, applying then the cosine similarity on the matrix we got the final matrix ready to be evaluated. The Ide was Eclipse and the language Java, with a lot of supporting library.
%	\item Results Validation. At this stage we started the evaluation phase which consisted in a user study. We asked to a group of 10 people with experencie in Java delepoment, to rate a pull of queries provided by us. The results confirmed that CrossSim is a more precise method to calculate similarity with rispect to Clan and MudaBlue.
%\end{itemize}

%%%%%Future Works%%%%%

%Since the evualation was succesfully, in the sense that, results confirmed that CrossSim is a valuable similarity approach, the idea is to continue the development of the other features that still are missing (e.g. Code snippet suggestion, Api reccomandation).

%In order to provide such a baseline was mandatory to find some similar approach, we decided to use MudaBlue and Clan which are two close approaches, since there weren't any implementation available we re-implemented them from scratch. The contribute can be summarized as follows:

%Measuring similarities between software systems has been considered as a daunting task \cite{Chen:2015:SFD:2684822.2685305},\cite{McMillan:2012:DSS:2337223.2337267}. Furthermore, considering the miscellaneousness of artifacts in open source software repositories, similarity computation becomes more complicated as many artifacts and several cross relationships prevail. Given the circumstances, choosing the right tool to compute software similarity is a question that may arise at any time. To this end, the current thesis attempts to address one of the issues in software similarity computation by performing a comprehensive evaluation on various techniques. In particular, we re-implement four software similarity tools and conduct an empirical evaluation using a dataset collected from GitHub.